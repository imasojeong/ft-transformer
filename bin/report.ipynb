{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "italian-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "REPO_DIR = os.path.abspath('..')  # path to the root of the repository\n",
    "sys.path.append(REPO_DIR)\n",
    "os.environ[\"PROJECT_DIR\"] = REPO_DIR\n",
    "import lib\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "warming-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "EQ = 'EQ'\n",
    "JDT = 'JDT'\n",
    "LC = 'LC'\n",
    "APACHE = 'apache'\n",
    "SAFE = 'safe'\n",
    "ZXING = 'zxing'\n",
    "ALL_DATASETS = [EQ, JDT, LC, APACHE, SAFE, ZXING]\n",
    "DATASET_NAMES = {\n",
    "    EQ: 'EQ',\n",
    "    JDT: 'JDT',\n",
    "    LC: 'LC',\n",
    "    APACHE: 'apache',\n",
    "    SAFE: 'safe',\n",
    "    ZXING: 'zxing',\n",
    "}\n",
    "REGRESSION_DATASETS = [x for x in ALL_DATASETS if lib.load_dataset_info(x)['task_type'] == lib.REGRESSION]\n",
    "DETAILS = ['task_type', 'n_objects', 'n_features']\n",
    "PARTS = ['test', 'val', 'train']\n",
    "\n",
    "\n",
    "def format_scores(df, precision):\n",
    "    def f(record):\n",
    "        if record['task_type'] == lib.REGRESSION:\n",
    "            for part in PARTS:\n",
    "                for suffix in 'best', 'score':\n",
    "                    key = f'{part}_{suffix}'\n",
    "                    if key in record:\n",
    "                        record[key] *= -1\n",
    "        for k, v in list(record.items()):\n",
    "            if isinstance(v, float):\n",
    "                record[k] = round(v, precision)\n",
    "        return record\n",
    "    return df.apply(f, axis=1)\n",
    "\n",
    "\n",
    "def load_record(output):\n",
    "    output = Path(output)\n",
    "    if not output.exists():\n",
    "        return None\n",
    "    path = output / 'stats.json'\n",
    "    if not path.exists():\n",
    "        print(f'WARNING! This path does not exist: {path}')\n",
    "        return None\n",
    "    stats = lib.load_json(path)\n",
    "    metrics = stats.get('metrics')\n",
    "    if metrics is None:\n",
    "        return None\n",
    "\n",
    "    dataset = Path(stats['dataset']).name\n",
    "    info = lib.load_dataset_info(dataset)\n",
    "    dataset, algorithm_name, experiment, suffix = str(output.relative_to(lib.env.OUTPUT_DIR)).split('\\\\', 4)\n",
    "    r = {\n",
    "        'dataset': DATASET_NAMES[dataset],\n",
    "        'task_type': info['task_type'],\n",
    "        'n_objects': info['size'],\n",
    "        'n_features': info['n_num_features'] + info['n_cat_features'],\n",
    "        'algorithm': algorithm_name + f' | {experiment}',\n",
    "        's': suffix\n",
    "    }\n",
    "    for x in PARTS:\n",
    "        if x in stats['metrics']:\n",
    "            r[f'{x}_score'] = stats['metrics'][x]['PD']\n",
    "    return r\n",
    "\n",
    "\n",
    "def sort(df, by):\n",
    "    if isinstance(by, str):\n",
    "        by = [by]\n",
    "    return df.sort_values(['n_objects'] + by, ascending=[True] + ['score' not in x for x in by]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def make_df(outputs_and_names):\n",
    "    df = []\n",
    "    for output, algorithm_name in outputs_and_names:\n",
    "        record = load_record(output)\n",
    "        if not record:\n",
    "            continue\n",
    "        if algorithm_name is not None:\n",
    "            record['algorithm'] = algorithm_name\n",
    "        df.append(record)\n",
    "    df = sort(pd.DataFrame(df).fillna(0.0), 'val_score').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def collect_outputs(experiment_dir, filter_info=None):\n",
    "    if isinstance(filter_info, int):\n",
    "        filter_info = [str(x) for x in range(filter_info)]\n",
    "    if isinstance(filter_info, list):\n",
    "        assert all(isinstance(x, str) for x in filter_info)\n",
    "        filter_fn = lambda x: x.name in filter_info\n",
    "    elif callable(filter_info):\n",
    "        filter_fn = filter_info\n",
    "    else:\n",
    "        assert filter_info is None\n",
    "        filter_fn = lambda x: True\n",
    "\n",
    "    outputs = []\n",
    "    if not isinstance(experiment_dir, Path):\n",
    "        experiment_dir = lib.env.OUTPUT_DIR / experiment_dir\n",
    "    if experiment_dir.exists():\n",
    "        outputs.extend(\n",
    "            filter(\n",
    "                filter_fn,\n",
    "                filter(Path.is_dir, experiment_dir.iterdir())\n",
    "            )\n",
    "        )\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def aggregate(df):\n",
    "    aggrs = dict(\n",
    "        task_type=('task_type', 'first'),\n",
    "        n_objects=('n_objects', 'first'),\n",
    "        n_features=('n_features', 'first'),\n",
    "        test_score=('test_score', 'mean'),\n",
    "        test_std=('test_score', 'std'),\n",
    "        val_score=('val_score', 'mean'),\n",
    "        val_std=('val_score', 'std'),\n",
    "        count=('test_score', 'count')\n",
    "    )\n",
    "    if 'train_score' in df.columns:\n",
    "        aggrs.update(dict(\n",
    "            train_score=('train_score', 'mean'),\n",
    "            train_std=('train_score', 'std'),\n",
    "        ))\n",
    "    df = df.groupby(['dataset', 'algorithm']).agg(**aggrs)\n",
    "    df['count'] = df['count'].astype(int)\n",
    "    return df.reset_index().fillna(0.0)\n",
    "\n",
    "\n",
    "def build_report(outputs_and_names):\n",
    "    df = make_df(outputs_and_names)\n",
    "    df = aggregate(df)\n",
    "    df = sort(df, 'test_score')\n",
    "    df = format_scores(df, 4)\n",
    "    # df = df.set_index(['dataset', 'algorithm']).drop(columns=DETAILS)\n",
    "    df = df.set_index(['dataset'] + DETAILS + ['algorithm'])\n",
    "    return df[['test_score', 'val_score', 'train_score']]\n",
    "    # return df[['test_score', 'test_std', 'val_score', 'val_std', 'train_score', 'train_std', 'count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71032613-661b-43e9-8c8d-ebd25c3c7bb3",
   "metadata": {},
   "source": [
    "## Default configurations (GBDT and FT-Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "1383780d-db31-4551-83ff-a0b787de34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_datasets = set(deepcopy(ALL_DATASETS))\n",
    "# n_seeds = 15\n",
    "# ensemble_names = ['0_4', '5_9', '10_14']\n",
    "# outputs_and_names = []\n",
    "# for experiment, algorithm_name, datasets in [\n",
    "#     ('ft_transformer/default', 'FT-Transformer', all_datasets),\n",
    "#     ('catboost/default', 'CatBoost', all_datasets),\n",
    "#     ('xgboost/default', 'XGBoost', all_datasets),\n",
    "# ]:\n",
    "#     for dataset in datasets:\n",
    "#         for output in collect_outputs(dataset + '/' + experiment, n_seeds):\n",
    "#             outputs_and_names.append((output, algorithm_name))\n",
    "#         for output in collect_outputs(dataset + '/' + experiment + '_ensemble', ensemble_names):\n",
    "#             outputs_and_names.append((output, '(e) ' + algorithm_name))\n",
    "# build_report(outputs_and_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8728223-1ed8-4b10-9887-4c128179bd07",
   "metadata": {},
   "source": [
    "## All Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0dfa65ee-df3c-43e9-99d6-a5c089201052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>task_type</th>\n",
       "      <th>n_objects</th>\n",
       "      <th>n_features</th>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LC</th>\n",
       "      <th>binclass</th>\n",
       "      <th>20640</th>\n",
       "      <th>61</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.8371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JDT</th>\n",
       "      <th>binclass</th>\n",
       "      <th>20640</th>\n",
       "      <th>61</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.8572</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.9281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxing</th>\n",
       "      <th>binclass</th>\n",
       "      <th>98050</th>\n",
       "      <th>26</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.7733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apache</th>\n",
       "      <th>binclass</th>\n",
       "      <th>98050</th>\n",
       "      <th>26</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQ</th>\n",
       "      <th>binclass</th>\n",
       "      <th>98050</th>\n",
       "      <th>61</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.7540</td>\n",
       "      <td>0.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>safe</th>\n",
       "      <th>binclass</th>\n",
       "      <th>98050</th>\n",
       "      <th>26</th>\n",
       "      <th>FT-Transformer | default</th>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.7971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 test_score  \\\n",
       "dataset task_type n_objects n_features algorithm                              \n",
       "LC      binclass  20640     61         FT-Transformer | default      0.9002   \n",
       "JDT     binclass  20640     61         FT-Transformer | default      0.8572   \n",
       "zxing   binclass  98050     26         FT-Transformer | default      0.7320   \n",
       "apache  binclass  98050     26         FT-Transformer | default      0.6970   \n",
       "EQ      binclass  98050     61         FT-Transformer | default      0.5207   \n",
       "safe    binclass  98050     26         FT-Transformer | default      0.4000   \n",
       "\n",
       "                                                                 val_score  \\\n",
       "dataset task_type n_objects n_features algorithm                             \n",
       "LC      binclass  20640     61         FT-Transformer | default     0.8846   \n",
       "JDT     binclass  20640     61         FT-Transformer | default     0.8645   \n",
       "zxing   binclass  98050     26         FT-Transformer | default     0.7860   \n",
       "apache  binclass  98050     26         FT-Transformer | default     0.6889   \n",
       "EQ      binclass  98050     61         FT-Transformer | default     0.7540   \n",
       "safe    binclass  98050     26         FT-Transformer | default     0.6933   \n",
       "\n",
       "                                                                 train_score  \n",
       "dataset task_type n_objects n_features algorithm                              \n",
       "LC      binclass  20640     61         FT-Transformer | default       0.8371  \n",
       "JDT     binclass  20640     61         FT-Transformer | default       0.9281  \n",
       "zxing   binclass  98050     26         FT-Transformer | default       0.7733  \n",
       "apache  binclass  98050     26         FT-Transformer | default       0.7755  \n",
       "EQ      binclass  98050     61         FT-Transformer | default       0.7866  \n",
       "safe    binclass  98050     26         FT-Transformer | default       0.7971  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets = set(deepcopy(ALL_DATASETS))\n",
    "n_seeds = 15\n",
    "outputs_and_names = []\n",
    "for experiment, algorithm_name, datasets in [\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [EQ]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-Transformer | tuned', [EQ]), #tuned_reproduced가 새로운 데이터세트에 튜닝한 것\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [JDT]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-Transformer | tuned', [JDT]),\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [LC]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-transformer | tuned', [LC]),\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [APACHE]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-transformer | tuned', [APACHE]),\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [SAFE]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-transformer | tuned', [SAFE]),\n",
    "    ('ft_transformer/default', 'FT-Transformer | default', [ZXING]),\n",
    "    ('ft_transformer/tuned_reproduced', 'FT-Transformer | tuned', [ZXING]),\n",
    "\n",
    "]:\n",
    "    for dataset in datasets:\n",
    "        for output in collect_outputs(dataset + '/' + experiment, n_seeds):\n",
    "            outputs_and_names.append((output, algorithm_name))\n",
    "build_report(outputs_and_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1371b5f-4dd2-42df-93ea-b52fde2d5af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Neural Networks and GDBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "23312c46-b789-4c49-8984-72fbc2e5c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_datasets = set(deepcopy(ALL_DATASETS))\n",
    "# n_seeds = 15\n",
    "# ensemble_names = ['0_4', '5_9', '10_14']\n",
    "# outputs_and_names = []\n",
    "# for experiment, algorithm_name, datasets in [\n",
    "#     ('mlp/tuned', 'MLP', all_datasets),\n",
    "#     ('resnet/tuned', 'ResNet', all_datasets),\n",
    "#     ('ft_transformer/tuned', 'FT-Transformer', all_datasets - {YAHOO}),\n",
    "#     ('ft_transformer/default', 'FT-Transformer | default', all_datasets),\n",
    "#     ('catboost/tuned', 'CatBoost', all_datasets),\n",
    "#     ('xgboost/tuned', 'XGBoost', all_datasets),\n",
    "#     ('lightgbm_/tuned', 'LightGBM', {CALIFORNIA, ADULT, HIGGS}),\n",
    "# ]:\n",
    "#     for dataset in datasets:\n",
    "#         for output in collect_outputs(dataset + '/' + experiment, n_seeds):\n",
    "#             outputs_and_names.append((output, algorithm_name))\n",
    "#         for output in collect_outputs(dataset + '/' + experiment + '_ensemble', ensemble_names):\n",
    "#             outputs_and_names.append((output, '(e) ' + algorithm_name))\n",
    "# build_report(outputs_and_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9429c-065d-47c0-84a8-2778880b23ca",
   "metadata": {},
   "source": [
    "## Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3bc3be60-14f0-45bf-b5de-0fa9d72cf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_datasets = {CALIFORNIA, HELENA, JANNIS, HIGGS, ALOI, YEAR, COVTYPE, MICROSOFT}\n",
    "# n_seeds = 15\n",
    "# outputs_and_names = []\n",
    "# for experiment, algorithm_name, datasets in [\n",
    "#     ('autoint/tuned', 'AutoInt', all_datasets),\n",
    "#     ('ft_transformer/tuned_nobias', 'FT-Transformer | nobias', all_datasets),\n",
    "#     ('ft_transformer/tuned', 'FT-Transformer', all_datasets),\n",
    "# ]:\n",
    "#     for dataset in datasets:\n",
    "#         for output in collect_outputs(dataset + '/' + experiment, n_seeds):\n",
    "#             outputs_and_names.append((output, algorithm_name))\n",
    "# build_report(outputs_and_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4f71a-6b02-4adc-8aa1-4c1dee21278a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
